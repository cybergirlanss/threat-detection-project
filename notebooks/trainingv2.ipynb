{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 67/67 [00:04<00:00, 15.94it/s]\n",
      "Epoch 1: 100%|██████████| 780/780 [00:03<00:00, 221.77it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 1 | Train Loss: 1.4473 | Val Acc: 0.6973 | Val F1: 0.6911 | Val AUC: 0.9240\n",
      "Epoch 2: 100%|██████████| 780/780 [00:03<00:00, 253.16it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 2 | Train Loss: 0.9609 | Val Acc: 0.7335 | Val F1: 0.7302 | Val AUC: 0.9590\n",
      "Epoch 3: 100%|██████████| 780/780 [00:03<00:00, 238.28it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 3 | Train Loss: 0.8024 | Val Acc: 0.8164 | Val F1: 0.8219 | Val AUC: 0.9712\n",
      "Epoch 4: 100%|██████████| 780/780 [00:03<00:00, 222.80it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 4 | Train Loss: 0.6928 | Val Acc: 0.8581 | Val F1: 0.8626 | Val AUC: 0.9790\n",
      "Epoch 5: 100%|██████████| 780/780 [00:03<00:00, 223.32it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 5 | Train Loss: 0.6094 | Val Acc: 0.8745 | Val F1: 0.8789 | Val AUC: 0.9845\n",
      "Epoch 6: 100%|██████████| 780/780 [00:03<00:00, 224.42it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 6 | Train Loss: 0.5449 | Val Acc: 0.8765 | Val F1: 0.8790 | Val AUC: 0.9880\n",
      "Epoch 7: 100%|██████████| 780/780 [00:03<00:00, 221.67it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 7 | Train Loss: 0.5092 | Val Acc: 0.8911 | Val F1: 0.8944 | Val AUC: 0.9895\n",
      "Epoch 8: 100%|██████████| 780/780 [00:03<00:00, 221.18it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 8 | Train Loss: 0.4706 | Val Acc: 0.9012 | Val F1: 0.9059 | Val AUC: 0.9913\n",
      "Epoch 9: 100%|██████████| 780/780 [00:03<00:00, 222.46it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 9 | Train Loss: 0.4367 | Val Acc: 0.9041 | Val F1: 0.9080 | Val AUC: 0.9918\n",
      "Epoch 10: 100%|██████████| 780/780 [00:03<00:00, 222.66it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 10 | Train Loss: 0.4223 | Val Acc: 0.9073 | Val F1: 0.9114 | Val AUC: 0.9930\n",
      "Epoch 11: 100%|██████████| 780/780 [00:03<00:00, 221.54it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 11 | Train Loss: 0.3949 | Val Acc: 0.9105 | Val F1: 0.9153 | Val AUC: 0.9933\n",
      "Epoch 12: 100%|██████████| 780/780 [00:03<00:00, 223.95it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 12 | Train Loss: 0.3874 | Val Acc: 0.9093 | Val F1: 0.9135 | Val AUC: 0.9936\n",
      "Epoch 13: 100%|██████████| 780/780 [00:03<00:00, 223.02it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 13 | Train Loss: 0.3711 | Val Acc: 0.9107 | Val F1: 0.9149 | Val AUC: 0.9937\n",
      "Epoch 14: 100%|██████████| 780/780 [00:03<00:00, 225.57it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 14 | Train Loss: 0.3617 | Val Acc: 0.9150 | Val F1: 0.9196 | Val AUC: 0.9939\n",
      "Epoch 15: 100%|██████████| 780/780 [00:03<00:00, 227.02it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 15 | Train Loss: 0.3555 | Val Acc: 0.9128 | Val F1: 0.9172 | Val AUC: 0.9940\n",
      "Epoch 16: 100%|██████████| 780/780 [00:03<00:00, 226.39it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 16 | Train Loss: 0.3360 | Val Acc: 0.9161 | Val F1: 0.9208 | Val AUC: 0.9940\n",
      "Epoch 17: 100%|██████████| 780/780 [00:03<00:00, 223.41it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 17 | Train Loss: 0.3297 | Val Acc: 0.9144 | Val F1: 0.9188 | Val AUC: 0.9942\n",
      "Epoch 18: 100%|██████████| 780/780 [00:03<00:00, 217.18it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 18 | Train Loss: 0.3230 | Val Acc: 0.9155 | Val F1: 0.9198 | Val AUC: 0.9943\n",
      "Epoch 19: 100%|██████████| 780/780 [00:03<00:00, 223.49it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 19 | Train Loss: 0.3190 | Val Acc: 0.9149 | Val F1: 0.9192 | Val AUC: 0.9942\n",
      "Epoch 20: 100%|██████████| 780/780 [00:03<00:00, 221.81it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 20 | Train Loss: 0.3135 | Val Acc: 0.9157 | Val F1: 0.9200 | Val AUC: 0.9943\n",
      "Epoch 21: 100%|██████████| 780/780 [00:03<00:00, 217.74it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 21 | Train Loss: 0.3060 | Val Acc: 0.9147 | Val F1: 0.9190 | Val AUC: 0.9943\n",
      "Epoch 22: 100%|██████████| 780/780 [00:03<00:00, 224.47it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 22 | Train Loss: 0.3018 | Val Acc: 0.9169 | Val F1: 0.9213 | Val AUC: 0.9944\n",
      "Epoch 23: 100%|██████████| 780/780 [00:03<00:00, 222.98it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 23 | Train Loss: 0.3033 | Val Acc: 0.9181 | Val F1: 0.9228 | Val AUC: 0.9944\n",
      "Epoch 24: 100%|██████████| 780/780 [00:03<00:00, 225.70it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 24 | Train Loss: 0.2935 | Val Acc: 0.9181 | Val F1: 0.9228 | Val AUC: 0.9945\n",
      "Epoch 25: 100%|██████████| 780/780 [00:03<00:00, 226.11it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 25 | Train Loss: 0.2926 | Val Acc: 0.9186 | Val F1: 0.9233 | Val AUC: 0.9944\n",
      "Epoch 26: 100%|██████████| 780/780 [00:03<00:00, 225.00it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 26 | Train Loss: 0.2825 | Val Acc: 0.9189 | Val F1: 0.9236 | Val AUC: 0.9945\n",
      "Epoch 27: 100%|██████████| 780/780 [00:03<00:00, 225.28it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 27 | Train Loss: 0.2858 | Val Acc: 0.9219 | Val F1: 0.9269 | Val AUC: 0.9945\n",
      "Epoch 28: 100%|██████████| 780/780 [00:03<00:00, 216.50it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 28 | Train Loss: 0.2815 | Val Acc: 0.9192 | Val F1: 0.9239 | Val AUC: 0.9945\n",
      "Epoch 29: 100%|██████████| 780/780 [00:03<00:00, 220.43it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 29 | Train Loss: 0.2758 | Val Acc: 0.9222 | Val F1: 0.9273 | Val AUC: 0.9946\n",
      "Epoch 30: 100%|██████████| 780/780 [00:03<00:00, 219.60it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 30 | Train Loss: 0.2829 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9946\n",
      "Epoch 31: 100%|██████████| 780/780 [00:03<00:00, 206.85it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 31 | Train Loss: 0.2727 | Val Acc: 0.9200 | Val F1: 0.9248 | Val AUC: 0.9946\n",
      "Epoch 32: 100%|██████████| 780/780 [00:03<00:00, 216.05it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 32 | Train Loss: 0.2717 | Val Acc: 0.9202 | Val F1: 0.9249 | Val AUC: 0.9946\n",
      "Epoch 33: 100%|██████████| 780/780 [00:03<00:00, 221.74it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 33 | Train Loss: 0.2680 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9946\n",
      "Epoch 34: 100%|██████████| 780/780 [00:03<00:00, 224.56it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 34 | Train Loss: 0.2710 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9946\n",
      "Epoch 35: 100%|██████████| 780/780 [00:03<00:00, 207.92it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 35 | Train Loss: 0.2658 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9946\n",
      "Epoch 36: 100%|██████████| 780/780 [00:03<00:00, 207.37it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 36 | Train Loss: 0.2652 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9946\n",
      "Epoch 37: 100%|██████████| 780/780 [00:03<00:00, 213.06it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 37 | Train Loss: 0.2645 | Val Acc: 0.9202 | Val F1: 0.9249 | Val AUC: 0.9946\n",
      "Epoch 38: 100%|██████████| 780/780 [00:03<00:00, 219.96it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 38 | Train Loss: 0.2725 | Val Acc: 0.9198 | Val F1: 0.9246 | Val AUC: 0.9946\n",
      "Epoch 39: 100%|██████████| 780/780 [00:03<00:00, 222.91it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 39 | Train Loss: 0.2659 | Val Acc: 0.9198 | Val F1: 0.9246 | Val AUC: 0.9946\n",
      "Epoch 40: 100%|██████████| 780/780 [00:03<00:00, 208.19it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 40 | Train Loss: 0.2638 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9947\n",
      "Epoch 41: 100%|██████████| 780/780 [00:03<00:00, 214.80it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 41 | Train Loss: 0.2574 | Val Acc: 0.9198 | Val F1: 0.9246 | Val AUC: 0.9947\n",
      "Epoch 42: 100%|██████████| 780/780 [00:03<00:00, 224.80it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 42 | Train Loss: 0.2598 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9946\n",
      "Epoch 43: 100%|██████████| 780/780 [00:03<00:00, 221.25it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 43 | Train Loss: 0.2627 | Val Acc: 0.9202 | Val F1: 0.9249 | Val AUC: 0.9946\n",
      "Epoch 44: 100%|██████████| 780/780 [00:03<00:00, 221.87it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 44 | Train Loss: 0.2601 | Val Acc: 0.9202 | Val F1: 0.9249 | Val AUC: 0.9946\n",
      "Epoch 45: 100%|██████████| 780/780 [00:03<00:00, 226.74it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 45 | Train Loss: 0.2578 | Val Acc: 0.9202 | Val F1: 0.9249 | Val AUC: 0.9946\n",
      "Epoch 46: 100%|██████████| 780/780 [00:03<00:00, 226.06it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 46 | Train Loss: 0.2526 | Val Acc: 0.9234 | Val F1: 0.9283 | Val AUC: 0.9947\n",
      "Epoch 47: 100%|██████████| 780/780 [00:03<00:00, 224.61it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 47 | Train Loss: 0.2603 | Val Acc: 0.9232 | Val F1: 0.9281 | Val AUC: 0.9947\n",
      "Epoch 48: 100%|██████████| 780/780 [00:03<00:00, 219.63it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 48 | Train Loss: 0.2587 | Val Acc: 0.9232 | Val F1: 0.9281 | Val AUC: 0.9947\n",
      "Epoch 49: 100%|██████████| 780/780 [00:03<00:00, 222.82it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 49 | Train Loss: 0.2559 | Val Acc: 0.9202 | Val F1: 0.9249 | Val AUC: 0.9947\n",
      "Epoch 50: 100%|██████████| 780/780 [00:03<00:00, 222.16it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 50 | Train Loss: 0.2561 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 51: 100%|██████████| 780/780 [00:03<00:00, 218.04it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 51 | Train Loss: 0.2606 | Val Acc: 0.9229 | Val F1: 0.9278 | Val AUC: 0.9947\n",
      "Epoch 52: 100%|██████████| 780/780 [00:03<00:00, 212.60it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 52 | Train Loss: 0.2535 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9947\n",
      "Epoch 53: 100%|██████████| 780/780 [00:03<00:00, 219.25it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 53 | Train Loss: 0.2588 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9947\n",
      "Epoch 54: 100%|██████████| 780/780 [00:03<00:00, 223.48it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 54 | Train Loss: 0.2526 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 55: 100%|██████████| 780/780 [00:03<00:00, 222.80it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 55 | Train Loss: 0.2559 | Val Acc: 0.9200 | Val F1: 0.9248 | Val AUC: 0.9946\n",
      "Epoch 56: 100%|██████████| 780/780 [00:03<00:00, 209.16it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 56 | Train Loss: 0.2520 | Val Acc: 0.9230 | Val F1: 0.9280 | Val AUC: 0.9946\n",
      "Epoch 57: 100%|██████████| 780/780 [00:03<00:00, 222.30it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 57 | Train Loss: 0.2517 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9947\n",
      "Epoch 58: 100%|██████████| 780/780 [00:03<00:00, 218.50it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 58 | Train Loss: 0.2555 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 59: 100%|██████████| 780/780 [00:03<00:00, 218.48it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 59 | Train Loss: 0.2550 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9946\n",
      "Epoch 60: 100%|██████████| 780/780 [00:03<00:00, 224.40it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 60 | Train Loss: 0.2542 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 61: 100%|██████████| 780/780 [00:03<00:00, 221.51it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 61 | Train Loss: 0.2525 | Val Acc: 0.9234 | Val F1: 0.9283 | Val AUC: 0.9946\n",
      "Epoch 62: 100%|██████████| 780/780 [00:03<00:00, 222.49it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 62 | Train Loss: 0.2530 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 63: 100%|██████████| 780/780 [00:03<00:00, 224.93it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 63 | Train Loss: 0.2515 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9947\n",
      "Epoch 64: 100%|██████████| 780/780 [00:03<00:00, 225.41it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 64 | Train Loss: 0.2503 | Val Acc: 0.9234 | Val F1: 0.9283 | Val AUC: 0.9947\n",
      "Epoch 65: 100%|██████████| 780/780 [00:03<00:00, 223.15it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 65 | Train Loss: 0.2555 | Val Acc: 0.9234 | Val F1: 0.9283 | Val AUC: 0.9947\n",
      "Epoch 66: 100%|██████████| 780/780 [00:03<00:00, 223.74it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 66 | Train Loss: 0.2525 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 67: 100%|██████████| 780/780 [00:03<00:00, 224.25it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 67 | Train Loss: 0.2494 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9947\n",
      "Epoch 68: 100%|██████████| 780/780 [00:03<00:00, 221.07it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 68 | Train Loss: 0.2499 | Val Acc: 0.9234 | Val F1: 0.9283 | Val AUC: 0.9946\n",
      "Epoch 69: 100%|██████████| 780/780 [00:03<00:00, 224.97it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 69 | Train Loss: 0.2587 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9947\n",
      "Epoch 70: 100%|██████████| 780/780 [00:03<00:00, 222.93it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 70 | Train Loss: 0.2516 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 71: 100%|██████████| 780/780 [00:03<00:00, 225.28it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 71 | Train Loss: 0.2523 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9946\n",
      "Epoch 72: 100%|██████████| 780/780 [00:03<00:00, 224.70it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 72 | Train Loss: 0.2493 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9947\n",
      "Epoch 73: 100%|██████████| 780/780 [00:03<00:00, 216.72it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 73 | Train Loss: 0.2582 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 74: 100%|██████████| 780/780 [00:03<00:00, 224.47it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 74 | Train Loss: 0.2494 | Val Acc: 0.9234 | Val F1: 0.9283 | Val AUC: 0.9946\n",
      "Epoch 75: 100%|██████████| 780/780 [00:03<00:00, 228.07it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 75 | Train Loss: 0.2497 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 76: 100%|██████████| 780/780 [00:03<00:00, 223.79it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 76 | Train Loss: 0.2499 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9946\n",
      "Epoch 77: 100%|██████████| 780/780 [00:03<00:00, 226.51it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 77 | Train Loss: 0.2488 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 78: 100%|██████████| 780/780 [00:03<00:00, 225.40it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 78 | Train Loss: 0.2468 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 79: 100%|██████████| 780/780 [00:03<00:00, 225.61it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 79 | Train Loss: 0.2437 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 80: 100%|██████████| 780/780 [00:03<00:00, 224.97it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 80 | Train Loss: 0.2521 | Val Acc: 0.9205 | Val F1: 0.9253 | Val AUC: 0.9947\n",
      "Epoch 81: 100%|██████████| 780/780 [00:03<00:00, 227.14it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Epoch 81 | Train Loss: 0.2524 | Val Acc: 0.9203 | Val F1: 0.9251 | Val AUC: 0.9947\n",
      "Epoch 82: 100%|██████████| 780/780 [00:03<00:00, 226.91it/s]\n",
      "INFO:__main__:Prediction shape: (6237, 8), Label shape: (6237, 1)\n",
      "INFO:__main__:Early stopping triggered\n",
      "INFO:__main__:Training complete. Best validation AUC: 0.9947\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# -------------------- Configuration -------------------- #\n",
    "CONFIG = {\n",
    "    \"data_dir\": r\"D:\\CLASS NOTES\\EPICS\\Model Dataset\\Extracted_features\",\n",
    "    \"model_save_path\": \"final_model.pth\",\n",
    "    \"scaler_save_path\": \"final_scaler.joblib\",\n",
    "    \"feature_dims\": {\n",
    "        \"spatial\": 36,    # 12 body joints * 3 coordinates (x,y,z)\n",
    "        \"temporal\": 10,   # 5 body parts * 2 features (velocity, acceleration)\n",
    "        \"tracked\": 3,     # 3 interaction metrics\n",
    "        \"group\": 1        # 1 group metric\n",
    "    },\n",
    "    \"interaction_weights\": {\n",
    "        \"tracked\": 2.5,\n",
    "        \"group\": 3.0\n",
    "    },\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 100,\n",
    "    \"early_stop_patience\": 10,\n",
    "    \"hidden_size\": 512,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"class_pattern\": r\"^([A-Za-z]+)\\d+\",\n",
    "    \"min_samples_per_class\": 2,\n",
    "    \"smote_sampling_strategy\": \"not minority\"\n",
    "}\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------- Feature Processing -------------------- #\n",
    "def parse_features(feature_str):\n",
    "    \"\"\"Recursively flatten nested JSON structures to float values\"\"\"\n",
    "    try:\n",
    "        data = json.loads(feature_str)\n",
    "        \n",
    "        def flatten(value):\n",
    "            if isinstance(value, dict):\n",
    "                return [item for v in value.values() for item in flatten(v)]\n",
    "            if isinstance(value, list):\n",
    "                return [item for sublist in value for item in flatten(sublist)]\n",
    "            try:\n",
    "                return [float(value)]\n",
    "            except:\n",
    "                return []\n",
    "        \n",
    "        return flatten(data)\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Parse error in '{feature_str[:50]}...': {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def pad_features(features, target_length):\n",
    "    \"\"\"Pad features with zeros to target length\"\"\"\n",
    "    return features[:target_length] + [0.0] * max(target_length - len(features), 0)\n",
    "\n",
    "# -------------------- Dataset Class -------------------- #\n",
    "class AnomalyDataset(Dataset):\n",
    "    def __init__(self, features, labels, scaler=None):\n",
    "        # Filter empty entries\n",
    "        valid_indices = [i for i, f in enumerate(features) if len(f) > 0]\n",
    "        features = [features[i] for i in valid_indices]\n",
    "        labels = [labels[i] for i in valid_indices]\n",
    "        \n",
    "        # Normalization\n",
    "        self.scaler = scaler or StandardScaler()\n",
    "        if scaler is None:\n",
    "            self.scaler.fit(features)\n",
    "        \n",
    "        self.features = self.scaler.transform(features)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.features[idx]).to(device),\n",
    "            torch.LongTensor([self.labels[idx]]).to(device)\n",
    "        )\n",
    "\n",
    "# -------------------- Model Architecture -------------------- #\n",
    "class InteractionAwareModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# -------------------- Data Loading Pipeline -------------------- #\n",
    "def load_and_process_data():\n",
    "    \"\"\"Full data processing pipeline with error handling\"\"\"\n",
    "    feature_files = [os.path.join(CONFIG['data_dir'], f) \n",
    "                   for f in os.listdir(CONFIG['data_dir']) if f.endswith('.csv')]\n",
    "    \n",
    "    # Class analysis and filtering\n",
    "    class_counts = defaultdict(int)\n",
    "    valid_files = []\n",
    "    for f in feature_files:\n",
    "        try:\n",
    "            cls_name = re.match(CONFIG['class_pattern'], os.path.basename(f)).group(1).lower()\n",
    "            class_counts[cls_name] += 1\n",
    "            valid_files.append(f)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    valid_classes = [cls for cls, count in class_counts.items() \n",
    "                    if count >= CONFIG['min_samples_per_class']]\n",
    "    \n",
    "    # Feature extraction\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    label_mapping = {cls: idx for idx, cls in enumerate(sorted(valid_classes))}\n",
    "    \n",
    "    for f in tqdm(valid_files, desc=\"Processing files\"):\n",
    "        try:\n",
    "            cls_name = re.match(CONFIG['class_pattern'], os.path.basename(f)).group(1).lower()\n",
    "            if cls_name not in valid_classes:\n",
    "                continue\n",
    "            \n",
    "            df = pd.read_csv(f)\n",
    "            label = label_mapping[cls_name]\n",
    "            \n",
    "            for _, row in df.iterrows():\n",
    "                # Parse and pad features\n",
    "                spatial = pad_features(parse_features(row['spatial']), CONFIG['feature_dims']['spatial'])\n",
    "                temporal = pad_features(parse_features(row['temporal']), CONFIG['feature_dims']['temporal'])\n",
    "                tracked = pad_features(parse_features(row['tracked']), CONFIG['feature_dims']['tracked'])\n",
    "                group = pad_features(parse_features(row['group']), CONFIG['feature_dims']['group'])\n",
    "                \n",
    "                # Apply interaction weights\n",
    "                interaction_feats = [\n",
    "                    tracked[0] * CONFIG['interaction_weights']['tracked'],\n",
    "                    tracked[1],\n",
    "                    tracked[2],\n",
    "                    group[0] * CONFIG['interaction_weights']['group']\n",
    "                ]\n",
    "                \n",
    "                # Combine features\n",
    "                combined = np.concatenate([spatial, temporal, interaction_feats])\n",
    "                all_features.append(combined)\n",
    "                all_labels.append(label)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {os.path.basename(f)}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return np.array(all_features), np.array(all_labels), label_mapping\n",
    "\n",
    "# -------------------- Training Pipeline -------------------- #\n",
    "def train():\n",
    "    # Load and validate data\n",
    "    X, y, label_mapping = load_and_process_data()\n",
    "    if len(X) == 0:\n",
    "        raise ValueError(\"No valid features extracted. Verify data files and parsing logic.\")\n",
    "    \n",
    "    # Balance classes\n",
    "    smote = SMOTE(sampling_strategy=CONFIG['smote_sampling_strategy'], random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    \n",
    "    # Split dataset\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_res, y_res, \n",
    "        test_size=0.2, \n",
    "        stratify=y_res,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = AnomalyDataset(X_train, y_train)\n",
    "    val_dataset = AnomalyDataset(X_val, y_val, train_dataset.scaler)\n",
    "    \n",
    "    # Save artifacts\n",
    "    joblib.dump(train_dataset.scaler, CONFIG['scaler_save_path'])\n",
    "    joblib.dump(label_mapping, 'label_mapping.joblib')\n",
    "    \n",
    "    # Initialize model\n",
    "    model = InteractionAwareModel(\n",
    "        input_size=X.shape[1],\n",
    "        num_classes=len(label_mapping)\n",
    "    ).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    \n",
    "    # Class-weighted loss\n",
    "    class_counts = np.bincount(y_train)\n",
    "    weights = torch.FloatTensor(1.0 / (class_counts + 1e-9)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    \n",
    "    # Training loop\n",
    "    best_auc = 0\n",
    "    no_improve = 0\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'])\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels.squeeze())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                outputs = model(features)\n",
    "                val_preds.extend(torch.softmax(outputs, 1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_labels = np.array(val_labels)\n",
    "        val_preds = np.array(val_preds)\n",
    "\n",
    "        logger.info(f\"Prediction shape: {val_preds.shape}, Label shape: {val_labels.shape}\")\n",
    "\n",
    "        metrics = {\n",
    "            'acc': accuracy_score(val_labels, np.argmax(val_preds, axis=1)),\n",
    "            'f1': f1_score(val_labels, np.argmax(val_preds, axis=1), average='weighted'),\n",
    "            'auc': roc_auc_score(val_labels, val_preds, multi_class='ovr', average='weighted')  # Changed to 'ovr'\n",
    "        }\n",
    "        \n",
    "        # Early stopping\n",
    "        if metrics['auc'] > best_auc:\n",
    "            best_auc = metrics['auc']\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), CONFIG['model_save_path'])\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= CONFIG['early_stop_patience']:\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                break\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "            f\"Val Acc: {metrics['acc']:.4f} | Val F1: {metrics['f1']:.4f} | Val AUC: {metrics['auc']:.4f}\"\n",
    "        )\n",
    "    \n",
    "    logger.info(f\"Training complete. Best validation AUC: {best_auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the feature processing loop:\n",
    "tracked = parse_features(row['tracked'])\n",
    "group = parse_features(row['group'])\n",
    "\n",
    "# Convert to floats and validate\n",
    "try:\n",
    "    tracked = [float(x) for x in tracked]\n",
    "    group = [float(x) for x in group]\n",
    "except ValueError as e:\n",
    "    logger.error(f\"Non-numeric value in {f}: {str(e)}\")\n",
    "    continue\n",
    "\n",
    "interaction_feats = [\n",
    "    tracked[0] * CONFIG['interaction_weights']['tracked'],\n",
    "    tracked[1],  # Already converted to float\n",
    "    tracked[2],\n",
    "    group[0] * CONFIG['interaction_weights']['group']\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
