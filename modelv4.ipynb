{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2428.3ms\n",
      "Speed: 7.7ms preprocess, 2428.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2422.5ms\n",
      "Speed: 9.0ms preprocess, 2422.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2382.4ms\n",
      "Speed: 8.4ms preprocess, 2382.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2347.7ms\n",
      "Speed: 7.0ms preprocess, 2347.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2352.3ms\n",
      "Speed: 8.0ms preprocess, 2352.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2379.2ms\n",
      "Speed: 8.0ms preprocess, 2379.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2348.4ms\n",
      "Speed: 7.7ms preprocess, 2348.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2349.9ms\n",
      "Speed: 8.1ms preprocess, 2349.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   4%|▍         | 1/25 [00:27<10:49, 27.06s/it, loss=1.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2431.8ms\n",
      "Speed: 9.0ms preprocess, 2431.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2416.9ms\n",
      "Speed: 6.3ms preprocess, 2416.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2415.3ms\n",
      "Speed: 7.0ms preprocess, 2415.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2417.1ms\n",
      "Speed: 8.9ms preprocess, 2417.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2419.1ms\n",
      "Speed: 7.4ms preprocess, 2419.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2423.1ms\n",
      "Speed: 6.4ms preprocess, 2423.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2412.4ms\n",
      "Speed: 9.4ms preprocess, 2412.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2418.6ms\n",
      "Speed: 7.0ms preprocess, 2418.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   8%|▊         | 2/25 [00:51<09:48, 25.57s/it, loss=88]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2415.8ms\n",
      "Speed: 9.0ms preprocess, 2415.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2417.3ms\n",
      "Speed: 8.0ms preprocess, 2417.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2415.7ms\n",
      "Speed: 7.1ms preprocess, 2415.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2412.6ms\n",
      "Speed: 8.0ms preprocess, 2412.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2416.7ms\n",
      "Speed: 8.0ms preprocess, 2416.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2415.2ms\n",
      "Speed: 7.5ms preprocess, 2415.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2412.3ms\n",
      "Speed: 8.5ms preprocess, 2412.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2422.6ms\n",
      "Speed: 8.0ms preprocess, 2422.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  12%|█▏        | 3/25 [01:16<09:11, 25.08s/it, loss=113]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2422.1ms\n",
      "Speed: 8.0ms preprocess, 2422.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2419.1ms\n",
      "Speed: 8.1ms preprocess, 2419.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2422.2ms\n",
      "Speed: 9.0ms preprocess, 2422.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2420.3ms\n",
      "Speed: 6.0ms preprocess, 2420.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2420.5ms\n",
      "Speed: 7.6ms preprocess, 2420.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2420.8ms\n",
      "Speed: 7.4ms preprocess, 2420.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2419.9ms\n",
      "Speed: 7.0ms preprocess, 2419.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2423.5ms\n",
      "Speed: 9.0ms preprocess, 2423.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  16%|█▌        | 4/25 [01:40<08:42, 24.87s/it, loss=153]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2423.5ms\n",
      "Speed: 9.0ms preprocess, 2423.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2416.1ms\n",
      "Speed: 8.3ms preprocess, 2416.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2418.3ms\n",
      "Speed: 8.0ms preprocess, 2418.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2417.4ms\n",
      "Speed: 8.0ms preprocess, 2417.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2418.8ms\n",
      "Speed: 7.8ms preprocess, 2418.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2416.8ms\n",
      "Speed: 9.0ms preprocess, 2416.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2426.0ms\n",
      "Speed: 8.6ms preprocess, 2426.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2422.3ms\n",
      "Speed: 9.1ms preprocess, 2422.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  20%|██        | 5/25 [02:05<08:15, 24.76s/it, loss=145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2425.6ms\n",
      "Speed: 9.0ms preprocess, 2425.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2426.3ms\n",
      "Speed: 8.0ms preprocess, 2426.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2425.1ms\n",
      "Speed: 7.5ms preprocess, 2425.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2419.4ms\n",
      "Speed: 9.2ms preprocess, 2419.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2420.6ms\n",
      "Speed: 8.0ms preprocess, 2420.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2494.9ms\n",
      "Speed: 9.0ms preprocess, 2494.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2513.1ms\n",
      "Speed: 9.0ms preprocess, 2513.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2497.6ms\n",
      "Speed: 9.4ms preprocess, 2497.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  24%|██▍       | 6/25 [02:30<07:52, 24.85s/it, loss=133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2498.2ms\n",
      "Speed: 10.7ms preprocess, 2498.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2491.9ms\n",
      "Speed: 19.6ms preprocess, 2491.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2501.5ms\n",
      "Speed: 8.2ms preprocess, 2501.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2488.7ms\n",
      "Speed: 9.0ms preprocess, 2488.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2495.0ms\n",
      "Speed: 8.1ms preprocess, 2495.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2495.7ms\n",
      "Speed: 8.4ms preprocess, 2495.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2469.5ms\n",
      "Speed: 10.2ms preprocess, 2469.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2407.9ms\n",
      "Speed: 11.5ms preprocess, 2407.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  28%|██▊       | 7/25 [02:55<07:27, 24.88s/it, loss=132]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2353.8ms\n",
      "Speed: 9.0ms preprocess, 2353.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2379.4ms\n",
      "Speed: 8.3ms preprocess, 2379.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.3ms\n",
      "Speed: 8.3ms preprocess, 2363.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2358.2ms\n",
      "Speed: 8.2ms preprocess, 2358.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.8ms\n",
      "Speed: 9.0ms preprocess, 2363.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.9ms\n",
      "Speed: 10.0ms preprocess, 2360.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2358.6ms\n",
      "Speed: 15.0ms preprocess, 2358.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.5ms\n",
      "Speed: 13.0ms preprocess, 2359.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  32%|███▏      | 8/25 [03:19<06:59, 24.65s/it, loss=123]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2362.2ms\n",
      "Speed: 13.0ms preprocess, 2362.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2358.6ms\n",
      "Speed: 14.0ms preprocess, 2358.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.3ms\n",
      "Speed: 13.0ms preprocess, 2362.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2365.6ms\n",
      "Speed: 13.0ms preprocess, 2365.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.9ms\n",
      "Speed: 13.0ms preprocess, 2359.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.9ms\n",
      "Speed: 14.0ms preprocess, 2359.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2410.8ms\n",
      "Speed: 12.0ms preprocess, 2410.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2385.6ms\n",
      "Speed: 14.0ms preprocess, 2385.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  36%|███▌      | 9/25 [03:43<06:33, 24.57s/it, loss=127]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2373.7ms\n",
      "Speed: 11.0ms preprocess, 2373.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.1ms\n",
      "Speed: 16.0ms preprocess, 2360.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.4ms\n",
      "Speed: 11.3ms preprocess, 2360.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.3ms\n",
      "Speed: 12.0ms preprocess, 2362.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2365.9ms\n",
      "Speed: 14.0ms preprocess, 2365.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2365.2ms\n",
      "Speed: 12.0ms preprocess, 2365.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.9ms\n",
      "Speed: 12.0ms preprocess, 2363.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2353.7ms\n",
      "Speed: 11.0ms preprocess, 2353.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  40%|████      | 10/25 [04:07<06:07, 24.48s/it, loss=129]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2364.9ms\n",
      "Speed: 12.0ms preprocess, 2364.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.8ms\n",
      "Speed: 19.5ms preprocess, 2360.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.2ms\n",
      "Speed: 11.0ms preprocess, 2361.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2364.4ms\n",
      "Speed: 13.5ms preprocess, 2364.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2357.5ms\n",
      "Speed: 13.4ms preprocess, 2357.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.8ms\n",
      "Speed: 12.7ms preprocess, 2360.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.0ms\n",
      "Speed: 11.5ms preprocess, 2363.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.7ms\n",
      "Speed: 16.2ms preprocess, 2361.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  44%|████▍     | 11/25 [04:32<05:41, 24.41s/it, loss=126]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2363.8ms\n",
      "Speed: 14.0ms preprocess, 2363.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.7ms\n",
      "Speed: 11.6ms preprocess, 2363.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2369.1ms\n",
      "Speed: 11.5ms preprocess, 2369.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.8ms\n",
      "Speed: 12.0ms preprocess, 2362.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.4ms\n",
      "Speed: 12.6ms preprocess, 2360.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2370.8ms\n",
      "Speed: 12.0ms preprocess, 2370.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2438.4ms\n",
      "Speed: 13.0ms preprocess, 2438.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2415.7ms\n",
      "Speed: 14.0ms preprocess, 2415.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  48%|████▊     | 12/25 [04:56<05:17, 24.44s/it, loss=125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2425.2ms\n",
      "Speed: 10.0ms preprocess, 2425.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2413.8ms\n",
      "Speed: 9.4ms preprocess, 2413.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2408.3ms\n",
      "Speed: 8.5ms preprocess, 2408.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2417.2ms\n",
      "Speed: 9.0ms preprocess, 2417.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2437.8ms\n",
      "Speed: 9.3ms preprocess, 2437.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2436.5ms\n",
      "Speed: 9.0ms preprocess, 2436.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2436.8ms\n",
      "Speed: 10.0ms preprocess, 2436.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2415.6ms\n",
      "Speed: 8.0ms preprocess, 2415.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  52%|█████▏    | 13/25 [05:21<04:53, 24.46s/it, loss=120]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2412.9ms\n",
      "Speed: 9.0ms preprocess, 2412.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2387.9ms\n",
      "Speed: 8.1ms preprocess, 2387.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2364.2ms\n",
      "Speed: 7.1ms preprocess, 2364.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2366.3ms\n",
      "Speed: 8.0ms preprocess, 2366.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.9ms\n",
      "Speed: 7.8ms preprocess, 2363.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.0ms\n",
      "Speed: 10.0ms preprocess, 2361.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2367.3ms\n",
      "Speed: 8.0ms preprocess, 2367.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.6ms\n",
      "Speed: 8.0ms preprocess, 2362.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  56%|█████▌    | 14/25 [05:45<04:27, 24.33s/it, loss=116]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2362.7ms\n",
      "Speed: 10.0ms preprocess, 2362.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.2ms\n",
      "Speed: 9.5ms preprocess, 2359.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.7ms\n",
      "Speed: 8.3ms preprocess, 2361.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.6ms\n",
      "Speed: 8.0ms preprocess, 2362.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.9ms\n",
      "Speed: 8.2ms preprocess, 2360.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.1ms\n",
      "Speed: 9.0ms preprocess, 2361.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.4ms\n",
      "Speed: 10.0ms preprocess, 2362.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2357.5ms\n",
      "Speed: 9.0ms preprocess, 2357.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  60%|██████    | 15/25 [06:09<04:02, 24.24s/it, loss=112]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2362.3ms\n",
      "Speed: 10.0ms preprocess, 2362.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2369.5ms\n",
      "Speed: 7.2ms preprocess, 2369.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.7ms\n",
      "Speed: 7.0ms preprocess, 2363.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.1ms\n",
      "Speed: 9.0ms preprocess, 2361.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.5ms\n",
      "Speed: 10.0ms preprocess, 2361.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2361.8ms\n",
      "Speed: 8.6ms preprocess, 2361.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.0ms\n",
      "Speed: 8.4ms preprocess, 2360.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.0ms\n",
      "Speed: 7.0ms preprocess, 2363.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  64%|██████▍   | 16/25 [06:33<03:37, 24.17s/it, loss=110]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2367.1ms\n",
      "Speed: 9.1ms preprocess, 2367.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.6ms\n",
      "Speed: 9.0ms preprocess, 2360.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2362.2ms\n",
      "Speed: 9.0ms preprocess, 2362.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.9ms\n",
      "Speed: 7.6ms preprocess, 2363.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.5ms\n",
      "Speed: 9.0ms preprocess, 2360.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.0ms\n",
      "Speed: 8.0ms preprocess, 2363.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.3ms\n",
      "Speed: 8.0ms preprocess, 2363.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.8ms\n",
      "Speed: 8.0ms preprocess, 2359.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  68%|██████▊   | 17/25 [06:57<03:12, 24.12s/it, loss=106]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2363.7ms\n",
      "Speed: 9.0ms preprocess, 2363.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.7ms\n",
      "Speed: 7.0ms preprocess, 2363.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2358.5ms\n",
      "Speed: 8.0ms preprocess, 2358.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2358.1ms\n",
      "Speed: 9.3ms preprocess, 2358.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2357.6ms\n",
      "Speed: 7.0ms preprocess, 2357.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.2ms\n",
      "Speed: 9.3ms preprocess, 2359.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2364.5ms\n",
      "Speed: 9.0ms preprocess, 2364.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.8ms\n",
      "Speed: 9.3ms preprocess, 2363.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  72%|███████▏  | 18/25 [07:21<02:48, 24.08s/it, loss=106]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2356.1ms\n",
      "Speed: 8.0ms preprocess, 2356.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2363.2ms\n",
      "Speed: 8.0ms preprocess, 2363.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2356.8ms\n",
      "Speed: 9.1ms preprocess, 2356.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2372.3ms\n",
      "Speed: 8.0ms preprocess, 2372.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2359.9ms\n",
      "Speed: 9.0ms preprocess, 2359.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2353.2ms\n",
      "Speed: 9.0ms preprocess, 2353.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2356.4ms\n",
      "Speed: 8.4ms preprocess, 2356.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2358.4ms\n",
      "Speed: 8.1ms preprocess, 2358.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  76%|███████▌  | 19/25 [07:45<02:24, 24.03s/it, loss=103]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2362.5ms\n",
      "Speed: 8.4ms preprocess, 2362.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2364.9ms\n",
      "Speed: 7.0ms preprocess, 2364.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2356.4ms\n",
      "Speed: 9.2ms preprocess, 2356.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2360.3ms\n",
      "Speed: 8.0ms preprocess, 2360.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2390.3ms\n",
      "Speed: 7.5ms preprocess, 2390.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2421.0ms\n",
      "Speed: 9.0ms preprocess, 2421.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2434.8ms\n",
      "Speed: 8.0ms preprocess, 2434.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2413.2ms\n",
      "Speed: 8.0ms preprocess, 2413.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  80%|████████  | 20/25 [08:09<02:00, 24.13s/it, loss=101]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2421.2ms\n",
      "Speed: 8.0ms preprocess, 2421.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2400.9ms\n",
      "Speed: 8.0ms preprocess, 2400.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2386.9ms\n",
      "Speed: 8.3ms preprocess, 2386.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2445.5ms\n",
      "Speed: 8.0ms preprocess, 2445.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2391.3ms\n",
      "Speed: 9.1ms preprocess, 2391.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2395.2ms\n",
      "Speed: 10.5ms preprocess, 2395.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2394.1ms\n",
      "Speed: 8.0ms preprocess, 2394.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2403.3ms\n",
      "Speed: 10.2ms preprocess, 2403.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  84%|████████▍ | 21/25 [08:34<01:36, 24.24s/it, loss=98.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2493.0ms\n",
      "Speed: 11.5ms preprocess, 2493.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2458.9ms\n",
      "Speed: 9.0ms preprocess, 2458.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2468.5ms\n",
      "Speed: 7.9ms preprocess, 2468.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2436.3ms\n",
      "Speed: 8.0ms preprocess, 2436.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2461.6ms\n",
      "Speed: 8.5ms preprocess, 2461.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2451.0ms\n",
      "Speed: 11.3ms preprocess, 2451.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2447.4ms\n",
      "Speed: 10.0ms preprocess, 2447.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2491.9ms\n",
      "Speed: 10.9ms preprocess, 2491.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  88%|████████▊ | 22/25 [08:59<01:13, 24.45s/it, loss=95.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 2483.6ms\n",
      "Speed: 9.8ms preprocess, 2483.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2430.1ms\n",
      "Speed: 12.0ms preprocess, 2430.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2420.3ms\n",
      "Speed: 9.0ms preprocess, 2420.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  88%|████████▊ | 22/25 [09:09<01:14, 24.96s/it, loss=95.9]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 187\u001b[0m\n\u001b[0;32m    184\u001b[0m total_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m    185\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39mtotal_batches, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 120\u001b[0m, in \u001b[0;36mVideoDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    117\u001b[0m frames \u001b[38;5;241m=\u001b[39m frames\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    118\u001b[0m frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(frames, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m--> 120\u001b[0m feature_vector \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frames, torch\u001b[38;5;241m.\u001b[39mtensor(feature_vector, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_to_idx[label]\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(frame):\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract YOLO & Mediapipe features from a frame.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     humans \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_humans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     keypoints \u001b[38;5;241m=\u001b[39m extract_keypoints(frame)\n\u001b[0;32m     48\u001b[0m     human_bbox \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(humans)\u001b[38;5;241m.\u001b[39mflatten()[:\u001b[38;5;241m8\u001b[39m]  \u001b[38;5;66;03m# First 8 values (x1, y1, x2, y2, confidence, class, etc.)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m, in \u001b[0;36mdetect_humans\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_humans\u001b[39m(frame):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Detect humans using YOLOv8.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43myolo_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m     humans \u001b[38;5;241m=\u001b[39m [box\u001b[38;5;241m.\u001b[39mxyxy\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mboxes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(box\u001b[38;5;241m.\u001b[39mcls) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m humans\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:180\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    153\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    154\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    156\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:558\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:260\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(im0s)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprofilers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\ops.py:51\u001b[0m, in \u001b[0;36mProfile.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\ops.py:61\u001b[0m, in \u001b[0;36mProfile.time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get current time.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\yacoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:985\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    983\u001b[0m _lazy_init()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load YOLOv8 model\n",
    "yolo_model = YOLO(\"yolov8x.pt\")\n",
    "\n",
    "# Load Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def detect_humans(frame):\n",
    "    \"\"\"Detect humans using YOLOv8.\"\"\"\n",
    "    results = yolo_model(frame)[0]\n",
    "    humans = [box.xyxy.tolist() for box in results.boxes if int(box.cls) == 0]\n",
    "    return humans\n",
    "\n",
    "def extract_keypoints(frame):\n",
    "    \"\"\"Extract human keypoints using Mediapipe.\"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Ensure frame is uint8 with values in range [0, 255]\n",
    "    frame_rgb = (frame_rgb * 255).astype(np.uint8) if frame_rgb.dtype != np.uint8 else frame_rgb\n",
    "\n",
    "    results = pose.process(frame_rgb)\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            keypoints.append([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "    \n",
    "    return np.array(keypoints).flatten()\n",
    "\n",
    "\n",
    "def extract_features(frame):\n",
    "    \"\"\"Extract YOLO & Mediapipe features from a frame.\"\"\"\n",
    "    humans = detect_humans(frame)\n",
    "    keypoints = extract_keypoints(frame)\n",
    "\n",
    "    human_bbox = np.array(humans).flatten()[:8]  # First 8 values (x1, y1, x2, y2, confidence, class, etc.)\n",
    "    if len(human_bbox) < 8:\n",
    "        human_bbox = np.pad(human_bbox, (0, 8 - len(human_bbox)), mode=\"constant\")\n",
    "\n",
    "    # Ensure keypoints do not exceed 75\n",
    "    keypoints = keypoints[:75]  # Trim excess if necessary\n",
    "\n",
    "    # Pad keypoints only if they are fewer than 75\n",
    "    if len(keypoints) < 75:\n",
    "        keypoints = np.pad(keypoints, (0, 75 - len(keypoints)), mode=\"constant\")\n",
    "\n",
    "    return np.concatenate((human_bbox, keypoints))\n",
    "\n",
    "\n",
    "class C3D(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(C3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.bn2 = nn.BatchNorm3d(128)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.bn3 = nn.BatchNorm3d(256)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self._feature_size = self._get_conv_output()\n",
    "\n",
    "        self.fc1 = nn.Linear(self._feature_size, 512)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _get_conv_output(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 3, 16, 112, 112)\n",
    "            x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "            x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "            x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "            return int(np.prod(x.shape[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_paths, labels, sequence_length=16):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.sequence_length = sequence_length\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(set(labels))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        frames = self.load_frames(video_path)\n",
    "\n",
    "        frames = np.stack(frames, axis=0)\n",
    "        frames = frames.transpose(3, 0, 1, 2)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32) / 255.0\n",
    "\n",
    "        feature_vector = extract_features(frames[:, -1, :, :].permute(1, 2, 0).numpy())\n",
    "\n",
    "        return frames, torch.tensor(feature_vector, dtype=torch.float32), self.label_to_idx[label]\n",
    "\n",
    "    def load_frames(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (112, 112))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            if len(frames) == self.sequence_length:\n",
    "                break\n",
    "        cap.release()\n",
    "\n",
    "        while len(frames) < self.sequence_length:\n",
    "            frames.append(frames[-1])\n",
    "\n",
    "        return frames\n",
    "\n",
    "def extract_label(filename):\n",
    "    match = re.match(r\"^[^\\d]+\", filename)\n",
    "    return match.group(0).strip() if match else None\n",
    "\n",
    "def load_video_paths_and_labels(folder_path):\n",
    "    video_paths, labels = [], []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.mp4', '.avi', '.mov')):\n",
    "                video_path = os.path.join(root, file)\n",
    "                label = extract_label(file)\n",
    "                if label:\n",
    "                    video_paths.append(video_path)\n",
    "                    labels.append(label)\n",
    "    return video_paths, labels\n",
    "\n",
    "folder_path = \"D:/CLASS NOTES/EPICS/Model Dataset/Anomaly-Videos\"\n",
    "video_paths, labels = load_video_paths_and_labels(folder_path)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(video_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = VideoDataset(train_paths, train_labels)\n",
    "val_dataset = VideoDataset(val_paths, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "num_classes = len(set(labels))\n",
    "c3d_model = C3D(num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "c3d_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(c3d_model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    c3d_model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_loader)\n",
    "    pbar = tqdm(enumerate(train_loader), total=total_batches, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx, (inputs, features, labels) in pbar:\n",
    "        inputs, features, labels = inputs.to(device), features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = c3d_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=running_loss / (batch_idx + 1))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    c3d_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, features, labels in val_loader:\n",
    "            inputs, features, labels = inputs.to(device), features.to(device), labels.to(device)\n",
    "            outputs = c3d_model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "torch.save(c3d_model.state_dict(), 'c3d_anomaly_detection.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
